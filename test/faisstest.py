from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
import os

# âœ… ë¡œë“œí•  ë²¡í„°DB ì„¤ì •
law_name = "Criminal_Law"
FAISS_INDEX_DIR = os.path.abspath("../faiss_indexes")
index_path = os.path.join(FAISS_INDEX_DIR, law_name)

# âœ… SBERT ì„ë² ë”© ëª¨ë¸
embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli", model_kwargs={"device": "cpu"})

# âœ… FAISS ë²¡í„°DB ë¡œë“œ
print(f"\nğŸ“‚ {law_name} ë²¡í„°DBë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘... (ê²½ë¡œ: {index_path})")
vector_store = FAISS.load_local(index_path, embedding_model, allow_dangerous_deserialization=True)

# âœ… ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
query = "í­í–‰ì£„ ì²˜ë²Œ"  # ì¿¼ë¦¬ ìˆ˜ì •
top_k = 5
search_results = vector_store.similarity_search_with_score(query, k=top_k)

# âœ… ì ìˆ˜ ì •ê·œí™” (Cosine Similarity ë³€í™˜)
scores = [score for _, score in search_results]
min_score, max_score = min(scores), max(scores)

def normalize_score(score):
    return 1 - (score - min_score) / (max_score - min_score) if max_score > min_score else 1.0

# âœ… "í­í–‰"ì´ í¬í•¨ëœ ì¡°í•­ ìš°ì„  í•„í„°ë§
filtered_results = sorted(search_results, key=lambda x: ("í­í–‰" in x[0].metadata.get("article", ""), normalize_score(x[1])), reverse=True)

print(f"\nğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼ (Top {top_k}):")
for i, (result, score) in enumerate(filtered_results):
    normalized_score = normalize_score(score)  # ì ìˆ˜ ì •ê·œí™”
    article = result.metadata.get("article", "ì•Œ ìˆ˜ ì—†ìŒ")
    print(f"\n--- ğŸ”¹ ê²€ìƒ‰ ê²°ê³¼ {i+1} ---")
    print(f"ğŸ“Œ ì¶œì²˜: {result.metadata['source']} | ì¡°í•­: {article}")
    print(f"ğŸ“– ë‚´ìš©:\n{result.page_content}")
    print(f"ğŸ¯ ìœ ì‚¬ë„ ì ìˆ˜ (0~1): {normalized_score:.4f}")